{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os,json\n",
    "\n",
    "# Number of maximun parallel jobs defined by the number of CPUs\n",
    "import multiprocessing\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "# Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Kmeans unsupervised learning tool\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Split train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Label Encode\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Feature Scaling (normalize)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualization options\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step():\n",
    "    print()\n",
    "    print('02 - Step 0: Checking intensity JSON file')\n",
    "    print()\n",
    "    print('\\tChecking if intensity_info.json file already exists')\n",
    "    if not os.path.exists('intensity_info.json'):\n",
    "        print('\\t\\t---FALSE---')\n",
    "        print('\\tCreating JSON file')\n",
    "        print()\n",
    "        act_lab = {\n",
    "            1:{'name':'lying','intensity3':1,'intensity5':1},\n",
    "            2:{'name':'sitting','intensity3':1,'intensity5':1},\n",
    "            3:{'name':'standing','intensity3':1,'intensity5':2},\n",
    "            4:{'name':'walking','intensity3':2,'intensity5':2},\n",
    "            5:{'name':'running','intensity3':3,'intensity5':5},\n",
    "            6:{'name':'cycling','intensity3':3,'intensity5':4},\n",
    "            7:{'name':'Nordic walking','intensity3':3,'intensity5':3},\n",
    "            9:{'name':'watching TV','intensity3':1,'intensity5':1},\n",
    "            10:{'name':'computer work','intensity3':1,'intensity5':2},\n",
    "            11:{'name':'car driving','intensity3':2,'intensity5':2},\n",
    "            12:{'name':'ascending stairs','intensity3':2,'intensity5':4},\n",
    "            13:{'name':'descending stairs','intensity3':2,'intensity5':3},\n",
    "            16:{'name':'vacuum cleaning','intensity3':2,'intensity5':3},\n",
    "            17:{'name':'ironing','intensity3':1,'intensity5':2},\n",
    "            18:{'name':'folding laundry','intensity3':1,'intensity5':2},\n",
    "            19:{'name':'house cleaning','intensity3':2,'intensity5':3},\n",
    "            20:{'name':'playing soccer','intensity3':3,'intensity5':4},\n",
    "            24:{'name':'rope jumping','intensity3':3,'intensity5':5}\n",
    "        }\n",
    "        with open('intensity_info.json', 'w') as fp:\n",
    "            json.dump(act_lab, fp)\n",
    "        fp.close()\n",
    "        print('\\tIntensity info JSON file has been created')\n",
    "        print('\\tReturning to user the intensity data')\n",
    "        return act_lab\n",
    "    else:\n",
    "        print('\\t\\t---TRUE---')\n",
    "        print('\\tLoading JSON file')\n",
    "        print()\n",
    "        with open('intensity_info.json', 'r') as fp:\n",
    "            act_lab = json.load(fp)\n",
    "        print('\\tIntensity info JSON file has been loaded')\n",
    "        print('\\tReturning to user the intensity data')\n",
    "        return act_lab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data_from_pkl(file,act_lab):\n",
    "    print()\n",
    "    print('02 - Step 1')\n",
    "    print()\n",
    "    print('\\tReading file: ',file)\n",
    "    df = pd.read_pickle(file)\n",
    "    if sum([type(item)==str for item in act_lab.keys()])!=0:\n",
    "        df['Intensity3'] = list(map(lambda x: act_lab[str(x)]['intensity3'],df['Activity ID']))\n",
    "        df['Intensity5'] = list(map(lambda x: act_lab[str(x)]['intensity5'],df['Activity ID']))\n",
    "    else:\n",
    "        df['Intensity3'] = list(map(lambda x: act_lab[x]['intensity3'],df['Activity ID']))\n",
    "        df['Intensity5'] = list(map(lambda x: act_lab[x]['intensity5'],df['Activity ID']))\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler_pipe(data):\n",
    "    print()\n",
    "    print('02 - Step 2')\n",
    "    print()\n",
    "    print('\\tScaling Data (Standard Scaler)')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data);\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print('')\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "02 - Step 0: Checking intensity JSON file\n",
      "\n",
      "\tChecking if intensity_info.json file already exists\n",
      "\t\t---TRUE---\n",
      "\tLoading JSON file\n",
      "\n",
      "\tIntensity info JSON file has been loaded\n",
      "\tReturning to user the intensity data\n",
      "\n",
      "02 - Step 1\n",
      "\n",
      "\tReading file:  physical_activity.pkl\n",
      "\t\t>>DONE<<\n",
      "\n",
      "\n",
      "02 - Step 2\n",
      "\n",
      "\tScaling Data (Standard Scaler)\n",
      "\t\t>>DONE<<\n",
      "\n"
     ]
    }
   ],
   "source": [
    "act_lab = first_step()\n",
    "df = reading_data_from_pkl('physical_activity.pkl',act_lab)\n",
    "x = standard_scaler_pipe(df[[item for item in df.columns if item!='Activity ID' and item!='Intensity3' and item!='Intensity5']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "colors = ['blue','red','green','cyan','gold']\n",
    "list_clus = [2,3,4,5]\n",
    "for item in list_clus:\n",
    "    print()\n",
    "    print('Num of clusters: ',item)\n",
    "    print()\n",
    "    Kmodel = KMeans(n_clusters=item)\n",
    "    Kmodel.fit(x)\n",
    "    labs = np.unique(Kmodel.labels_)\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final['Klabels'] = Kmodel.labels_\n",
    "    if sum([type(item)==str for item in act_lab.keys()])!=0:\n",
    "        df_final['Intensity3'] = list(map(lambda x: act_lab[str(x)]['intensity3'],df['Activity ID']))\n",
    "        df_final['Intensity5'] = list(map(lambda x: act_lab[str(x)]['intensity5'],df['Activity ID']))\n",
    "    else:\n",
    "        df_final['Intensity3'] = list(map(lambda x: act_lab[x]['intensity3'],df['Activity ID']))\n",
    "        df_final['Intensity5'] = list(map(lambda x: act_lab[x]['intensity5'],df['Activity ID']))\n",
    "    fig = plt.figure(figsize=(7*len(labs),10))\n",
    "    counter = 0\n",
    "    for e in labs:\n",
    "        counter += 1\n",
    "        ax = plt.subplot(2,len(labs),counter)\n",
    "        n,c = np.unique(df_final[df_final['Klabels']==e]['Intensity3'],return_counts=True)\n",
    "        k = ax.bar(n,c)\n",
    "        counter1 = -1\n",
    "        for el in k:\n",
    "            counter1 += 1\n",
    "            if counter1>len(colors)-1:\n",
    "                counter1 = 0\n",
    "            el.set_facecolor(colors[counter1])\n",
    "        ax.set_xticks(n)\n",
    "        ax.yaxis.grid()\n",
    "        ax.set_title('Cluster '+str(e)+' Num of distinct Intensities '+str(len(n)))\n",
    "        ax.set_xlabel('Intensity')\n",
    "    for e in labs:\n",
    "        counter += 1\n",
    "        ax = plt.subplot(2,len(labs),counter)\n",
    "        n,c = np.unique(df_final[df_final['Klabels']==e]['Intensity5'],return_counts=True)\n",
    "        k = ax.bar(n,c)\n",
    "        counter1 = -1\n",
    "        for el in k:\n",
    "            counter1 += 1\n",
    "            if counter1>len(colors)-1:\n",
    "                counter1 = 0\n",
    "            el.set_facecolor(colors[counter1])\n",
    "        ax.set_xticks(n)\n",
    "        ax.yaxis.grid()\n",
    "        ax.set_title('Cluster '+str(e)+' Num of distinct Intensities '+str(len(n)))\n",
    "        ax.set_xlabel('Intensity')\n",
    "    plt.savefig('Figures/02-Kmeans_'+str(item)+'_clusters.png',dpi=100)\n",
    "    plt.show()\n",
    "    del Kmodel\n",
    "    del df_final\n",
    "    print()\n",
    "    print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_forest(df):\n",
    "    print()\n",
    "    print('02 - Step 3:')\n",
    "    print()\n",
    "    print('\\tSpliting and using Standard Scaler')\n",
    "    X = df[[item for item in df.columns if item!='Activity ID' and item!='Intensity3' and item!='Intensity5']].values\n",
    "    if 'Intensity3' in df.columns:\n",
    "        Y = df['Intensity3'].values\n",
    "    elif 'Intensity5' in df.columns:\n",
    "        Y = df['Intensity5'].values\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size = 0.25, random_state = 21)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    return X_train1, X_test1, y_train1, y_test1\n",
    "    \n",
    "def cats(num_of_cat,df):\n",
    "    if num_of_cat == '3':\n",
    "        X_train1, X_test1, y_train1, y_test1 = rand_forest(df[[item for item in df.columns if item!='Intensity5']])\n",
    "    elif num_of_cat == '5':\n",
    "        X_train1, X_test1, y_train1, y_test1 = rand_forest(df[[item for item in df.columns if item!='Intensity3']])\n",
    "    return X_train1, X_test1, y_train1, y_test1\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, accuracy, class_names, model, figsize = (10,8), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=plt.cm.pink_r)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    all_sample_title = model+' | Accuracy: '+str(accuracy)\n",
    "    plt.title(all_sample_title, size = 15)\n",
    "    plt.savefig('Figures/Random_forest_'+str(len(class_names))+'_categories.png',dpi=150)\n",
    "    plt.close('all')\n",
    "    \n",
    "def rand_forest_classifier(num_of_cat,df):\n",
    "    X_train1, X_test1, y_train1, y_test1 = cats(num_of_cat,df)\n",
    "    print()\n",
    "    print('02 - Step 4: Applying Random Forest Classifier')\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42, n_jobs=n_cpu)\n",
    "    print()\n",
    "    print('\\tTrainning')\n",
    "    classifier.fit(X_train1, y_train1)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    print('\\tPredicting')\n",
    "    y_pred1 = classifier.predict(X_test1)\n",
    "    accuracy_random = metrics.accuracy_score(y_test1, y_pred1)\n",
    "    cm_random = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    print('\\tPrinting confusion matrix')\n",
    "    if num_of_cat=='3':\n",
    "        print_confusion_matrix(cm_random,accuracy_random,df['Intensity3'].unique(),model='Random Forest')\n",
    "    elif num_of_cat=='5':\n",
    "        print_confusion_matrix(cm_random,accuracy_random,df['Intensity5'].unique(),model='Random Forest')\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    return classifier,accuracy_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION >> Do you want to analyze for 3 or 5 categories?(3/5)\t>>\t5\n"
     ]
    }
   ],
   "source": [
    "num_of_cat = input('QUESTION >> Do you want to analyze for 3 or 5 categories?(3/5)\\t>>\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "02 - Step 3:\n",
      "\n",
      "\tSpliting and using Standard Scaler\n",
      "\t\t>>DONE<<\n",
      "\n",
      "\n",
      "02 - Step 4: Applying Random Forest Classifier\n",
      "\n",
      "\tTrainning\n",
      "\t\t>>DONE<<\n",
      "\n",
      "\tPredicting\n",
      "\t\t>>DONE<<\n",
      "\n",
      "\tPrinting confusion matrix\n",
      "\t\t>>DONE<<\n",
      "\n",
      "\t>> Accuracy:  0.9997334332465017\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=8,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
      "\n",
      "CPU times: user 9min 40s, sys: 2.8 s, total: 9min 43s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model,accuracy = rand_forest_classifier(num_of_cat,df)\n",
    "print('\\t>> Accuracy: ',accuracy)\n",
    "print()\n",
    "print(model)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
