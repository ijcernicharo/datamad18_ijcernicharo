{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os,json\n",
    "\n",
    "# Number of maximun parallel jobs defined by the number of CPUs\n",
    "import multiprocessing\n",
    "n_cpu = multiprocessing.cpu_count()\n",
    "\n",
    "# Standard Scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Kmeans unsupervised learning tool\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Split train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# Label Encode\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Feature Scaling (normalize)\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# SVM\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Cross Validation\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Visualization options\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from IPython.display import display\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_step():\n",
    "    print()\n",
    "    print('02 - Step 0: Checking intensity JSON file')\n",
    "    print()\n",
    "    print('\\tChecking if intensity_info.json file already exists')\n",
    "    if not os.path.exists('intensity_info.json'):\n",
    "        print('\\t\\t---FALSE---')\n",
    "        print('\\tCreating JSON file')\n",
    "        print()\n",
    "        act_lab = {\n",
    "            1:{'name':'lying','intensity3':1,'intensity5':1},\n",
    "            2:{'name':'sitting','intensity3':1,'intensity5':1},\n",
    "            3:{'name':'standing','intensity3':1,'intensity5':2},\n",
    "            4:{'name':'walking','intensity3':2,'intensity5':2},\n",
    "            5:{'name':'running','intensity3':3,'intensity5':5},\n",
    "            6:{'name':'cycling','intensity3':3,'intensity5':4},\n",
    "            7:{'name':'Nordic walking','intensity3':3,'intensity5':3},\n",
    "            9:{'name':'watching TV','intensity3':1,'intensity5':1},\n",
    "            10:{'name':'computer work','intensity3':1,'intensity5':2},\n",
    "            11:{'name':'car driving','intensity3':2,'intensity5':2},\n",
    "            12:{'name':'ascending stairs','intensity3':2,'intensity5':4},\n",
    "            13:{'name':'descending stairs','intensity3':2,'intensity5':3},\n",
    "            16:{'name':'vacuum cleaning','intensity3':2,'intensity5':3},\n",
    "            17:{'name':'ironing','intensity3':1,'intensity5':2},\n",
    "            18:{'name':'folding laundry','intensity3':1,'intensity5':2},\n",
    "            19:{'name':'house cleaning','intensity3':2,'intensity5':3},\n",
    "            20:{'name':'playing soccer','intensity3':3,'intensity5':4},\n",
    "            24:{'name':'rope jumping','intensity3':3,'intensity5':5}\n",
    "        }\n",
    "        with open('intensity_info.json', 'w') as fp:\n",
    "            json.dump(act_lab, fp)\n",
    "        fp.close()\n",
    "        print('\\tIntensity info JSON file has been created')\n",
    "        print('\\tReturning to user the intensity data')\n",
    "        return act_lab\n",
    "    else:\n",
    "        print('\\t\\t---TRUE---')\n",
    "        print('\\tLoading JSON file')\n",
    "        print()\n",
    "        with open('intensity_info.json', 'r') as fp:\n",
    "            act_lab = json.load(fp)\n",
    "        print('\\tIntensity info JSON file has been loaded')\n",
    "        print('\\tReturning to user the intensity data')\n",
    "        return act_lab  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reading_data_from_pkl(file,act_lab):\n",
    "    print()\n",
    "    print('02 - Step 1')\n",
    "    print()\n",
    "    print('\\tReading file: ',file)\n",
    "    df = pd.read_pickle(file)\n",
    "    if sum([type(item)==str for item in act_lab.keys()])!=0:\n",
    "        df['Intensity3'] = list(map(lambda x: act_lab[str(x)]['intensity3'],df['Activity ID']))\n",
    "        df['Intensity5'] = list(map(lambda x: act_lab[str(x)]['intensity5'],df['Activity ID']))\n",
    "    else:\n",
    "        df['Intensity3'] = list(map(lambda x: act_lab[x]['intensity3'],df['Activity ID']))\n",
    "        df['Intensity5'] = list(map(lambda x: act_lab[x]['intensity5'],df['Activity ID']))\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print('')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_scaler_pipe(data):\n",
    "    print()\n",
    "    print('02 - Step 2')\n",
    "    print()\n",
    "    print('\\tScaling Data (Standard Scaler)')\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data);\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print('')\n",
    "    return scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_lab = first_step()\n",
    "df = reading_data_from_pkl('physical_activity.pkl',act_lab)\n",
    "x = standard_scaler_pipe(df[[item for item in df.columns if item!='Activity ID' and item!='Intensity3' and item!='Intensity5']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "colors = ['blue','red','green','cyan','gold']\n",
    "list_clus = [2,3,4,5]\n",
    "for item in list_clus:\n",
    "    print()\n",
    "    print('Num of clusters: ',item)\n",
    "    print()\n",
    "    Kmodel = KMeans(n_clusters=item)\n",
    "    Kmodel.fit(x)\n",
    "    labs = np.unique(Kmodel.labels_)\n",
    "    df_final = pd.DataFrame()\n",
    "    df_final['Klabels'] = Kmodel.labels_\n",
    "    if sum([type(item)==str for item in act_lab.keys()])!=0:\n",
    "        df_final['Intensity3'] = list(map(lambda x: act_lab[str(x)]['intensity3'],df['Activity ID']))\n",
    "        df_final['Intensity5'] = list(map(lambda x: act_lab[str(x)]['intensity5'],df['Activity ID']))\n",
    "    else:\n",
    "        df_final['Intensity3'] = list(map(lambda x: act_lab[x]['intensity3'],df['Activity ID']))\n",
    "        df_final['Intensity5'] = list(map(lambda x: act_lab[x]['intensity5'],df['Activity ID']))\n",
    "    fig = plt.figure(figsize=(7*len(labs),10))\n",
    "    counter = 0\n",
    "    for e in labs:\n",
    "        counter += 1\n",
    "        ax = plt.subplot(2,len(labs),counter)\n",
    "        n,c = np.unique(df_final[df_final['Klabels']==e]['Intensity3'],return_counts=True)\n",
    "        k = ax.bar(n,c)\n",
    "        counter1 = -1\n",
    "        for el in k:\n",
    "            counter1 += 1\n",
    "            if counter1>len(colors)-1:\n",
    "                counter1 = 0\n",
    "            el.set_facecolor(colors[counter1])\n",
    "        ax.set_xticks(n)\n",
    "        ax.yaxis.grid()\n",
    "        ax.set_title('Cluster '+str(e)+' Num of distinct Intensities '+str(len(n)))\n",
    "        ax.set_xlabel('Intensity')\n",
    "    for e in labs:\n",
    "        counter += 1\n",
    "        ax = plt.subplot(2,len(labs),counter)\n",
    "        n,c = np.unique(df_final[df_final['Klabels']==e]['Intensity5'],return_counts=True)\n",
    "        k = ax.bar(n,c)\n",
    "        counter1 = -1\n",
    "        for el in k:\n",
    "            counter1 += 1\n",
    "            if counter1>len(colors)-1:\n",
    "                counter1 = 0\n",
    "            el.set_facecolor(colors[counter1])\n",
    "        ax.set_xticks(n)\n",
    "        ax.yaxis.grid()\n",
    "        ax.set_title('Cluster '+str(e)+' Num of distinct Intensities '+str(len(n)))\n",
    "        ax.set_xlabel('Intensity')\n",
    "    plt.savefig('Figures/02-Kmeans_'+str(item)+'_clusters.png',dpi=100,bbox_inches='tight')\n",
    "    plt.show()\n",
    "    del Kmodel\n",
    "    del df_final\n",
    "    print()\n",
    "    print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_forest(df):\n",
    "    print()\n",
    "    print('02 - Step 3:')\n",
    "    print()\n",
    "    print('\\tSpliting and using Standard Scaler')\n",
    "    X = df[[item for item in df.columns if item!='Activity ID' and item!='Intensity3' and item!='Intensity5']].values\n",
    "    if 'Intensity3' in df.columns:\n",
    "        Y = df['Intensity3'].values\n",
    "    elif 'Intensity5' in df.columns:\n",
    "        Y = df['Intensity5'].values\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    X_train1, X_test1, y_train1, y_test1 = train_test_split(X, Y, test_size = 0.25, random_state = 21)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    return X_train1, X_test1, y_train1, y_test1\n",
    "    \n",
    "def cats(num_of_cat,df):\n",
    "    if num_of_cat == '3':\n",
    "        X_train1, X_test1, y_train1, y_test1 = rand_forest(df[[item for item in df.columns if item!='Intensity5']])\n",
    "    elif num_of_cat == '5':\n",
    "        X_train1, X_test1, y_train1, y_test1 = rand_forest(df[[item for item in df.columns if item!='Intensity3']])\n",
    "    return X_train1, X_test1, y_train1, y_test1\n",
    "\n",
    "def print_confusion_matrix(confusion_matrix, accuracy, class_names, model, figsize = (10,8), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=plt.cm.pink_r)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    all_sample_title = model+' | Accuracy: '+str(accuracy)\n",
    "    plt.title(all_sample_title, size = 15)\n",
    "    counter = 0\n",
    "    name = 'Figures/Random_forest_'+str(len(class_names))+'_categories-'+str(counter)+'.png'\n",
    "    if os.path.exists(name):\n",
    "        counter +=1\n",
    "        name = 'Figures/Random_forest_'+str(len(class_names))+'_categories-'+str(counter)+'.png'\n",
    "    plt.savefig('Figures/Random_forest_'+str(len(class_names))+'_categories.png',dpi=150,bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "    \n",
    "def rand_forest_classifier(num_of_cat,df):\n",
    "    X_train1, X_test1, y_train1, y_test1 = cats(num_of_cat,df)\n",
    "    print()\n",
    "    print('02 - Step 4: Applying Random Forest Classifier')\n",
    "    classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42, n_jobs=n_cpu, max_features = 'auto')\n",
    "    print()\n",
    "    print('\\tTrainning')\n",
    "    classifier.fit(X_train1, y_train1)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    print('\\tPredicting')\n",
    "    y_pred1 = classifier.predict(X_test1)\n",
    "    accuracy_random = metrics.accuracy_score(y_test1, y_pred1)\n",
    "    cm_random = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    print('\\tPrinting confusion matrix')\n",
    "    if num_of_cat=='3':\n",
    "        print_confusion_matrix(cm_random,accuracy_random,df['Intensity3'].unique(),model='Random Forest')\n",
    "    elif num_of_cat=='5':\n",
    "        print_confusion_matrix(cm_random,accuracy_random,df['Intensity5'].unique(),model='Random Forest')\n",
    "    print('\\t\\t>>DONE<<')\n",
    "    print()\n",
    "    return classifier,accuracy_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for item in ['3','5']:\n",
    "    print()\n",
    "    print('Num of categories of Intensity: '+item)\n",
    "    model,accuracy = rand_forest_classifier(item,df)\n",
    "    print('\\t>> Accuracy: ',accuracy)\n",
    "    print()\n",
    "    print(model)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRID SEARCH for RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x\n",
    "y = df['Intensity3'].values # For this study we go directly for the 5 category Intensity Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "\n",
    "param_grid = {\n",
    "    'max_features': [3,10],\n",
    "    'n_estimators': [10,20],\n",
    "    \"criterion\": [\"entropy\"]\n",
    "             }\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "print(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print()\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\" %(time() - start, len(grid_search.cv_results_['params'])))\n",
    "print()\n",
    "report(grid_search.cv_results_)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
