{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**You will find in this notebook some scrapy exercises to practise your scraping skills**.<br>**Remember:**\n",
    "- **To get each request status code to ensure you get the proper response from the web***\n",
    "- **To print the response text in each request to evaluate the what kind of info you are getting and its format.** \n",
    "- **To check for patterns in the response text to extract the data/info requested in each question.**\n",
    "- **To visit each url and take a look on its code through Chrome developer tool.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All the libraries and modules you will need are included below. Feel free to explore other libraries i.e. scrapy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup\n",
    "import scrapy\n",
    "from lxml import html\n",
    "from lxml.html import fromstring\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import re,os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Download and display the content of robot.txt for Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [here](http://www.robotstxt.org/robotstxt.html) to know more about ***robot.txt***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = \"https://en.wikipedia.org/robots.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the url all its info\n",
    "request=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><body><p># robots.txt for http://www.wikipedia.org/ and friends\n",
      "#\n",
      "# Please note: There are a lot of pages on this site, and there are\n",
      "# some misbehaved spiders out there that go _way_ too fast. If you're\n",
      "# irresponsible, your access to the site may be blocked.\n",
      "#\n",
      "\n",
      "# Observed spamming large amounts of https://en.wikipedia.org/?curid=NNNNNN\n",
      "# and ignoring 429 ratelimit responses, claims to respect robots:\n",
      "# http://mj12bot.com/\n",
      "User-agent: MJ12bot\n",
      "Disallow: /\n",
      "\n",
      "# advertising-related bots:\n",
      "User-agent: Mediapartners-Google*\n",
      "Disallow: /\n",
      "\n",
      "# Wikipedia work bots:\n",
      "User-agent: IsraBot\n",
      "Disallow:\n",
      "\n",
      "User-agent: Orthogaffe\n",
      "Disallow:\n",
      "\n",
      "# Crawlers that are kind enough to obey, but which we'd rather not have\n",
      "# unless they're feeding search engines.\n",
      "User-agent: UbiCrawler\n",
      "Disallow: /\n",
      "\n",
      "User-agent: DOC\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Zao\n",
      "Disallow: /\n",
      "\n",
      "# Some bots are known to be trouble, particularly those designed to copy\n",
      "# entire sites. Please obey robots.txt.\n",
      "User-agent: sitecheck.internetseer.com\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Zealbot\n",
      "Disallow: /\n",
      "\n",
      "User-agent: MSIECrawler\n",
      "Disallow: /\n",
      "\n",
      "User-agent: SiteSnagger\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebStripper\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebCopier\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Fetch\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Offline Explorer\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Teleport\n",
      "Disallow: /\n",
      "\n",
      "User-agent: TeleportPro\n",
      "Disallow: /\n",
      "\n",
      "User-agent: WebZIP\n",
      "Disallow: /\n",
      "\n",
      "User-agent: linko\n",
      "Disallow: /\n",
      "\n",
      "User-agent: HTTrack\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Microsoft.URL.Control\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Xenu\n",
      "Disallow: /\n",
      "\n",
      "User-agent: larbin\n",
      "Disallow: /\n",
      "\n",
      "User-agent: libwww\n",
      "Disallow: /\n",
      "\n",
      "User-agent: ZyBORG\n",
      "Disallow: /\n",
      "\n",
      "User-agent: Download Ninja\n",
      "Disallow: /\n",
      "\n",
      "# Misbehaving: requests much too fast:\n",
      "User-agent: fast\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Sorry, wget in its recursive mode is a frequent problem.\n",
      "# Please read the man page and use it properly; there is a\n",
      "# --wait option you can use to set the delay between hits,\n",
      "# for instance.\n",
      "#\n",
      "User-agent: wget\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# The 'grub' distributed client has been *very* poorly behaved.\n",
      "#\n",
      "User-agent: grub-client\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Doesn't follow robots.txt anyway, but...\n",
      "#\n",
      "User-agent: k2spider\n",
      "Disallow: /\n",
      "\n",
      "#\n",
      "# Hits many times per second, not acceptable\n",
      "# http://www.nameprotect.com/botinfo.html\n",
      "User-agent: NPBot\n",
      "Disallow: /\n",
      "\n",
      "# A capture bot, downloads gazillions of pages with no public benefit\n",
      "# http://www.webreaper.net/\n",
      "User-agent: WebReaper\n",
      "Disallow: /\n",
      "\n",
      "# Wayback Machine: defaults and whether to index user-pages\n",
      "# FIXME: Complete the removal of this block, per T7582.\n",
      "# User-agent: archive.org_bot\n",
      "# Allow: /\n",
      "\n",
      "\n",
      "#\n",
      "# Friendly, low-speed bots are welcome viewing article pages, but not\n",
      "# dynamically-generated pages please.\n",
      "#\n",
      "# Inktomi's \"Slurp\" can read a minimum delay between hits; if your\n",
      "# bot supports such a thing using the 'Crawl-delay' or another\n",
      "# instruction, please let us know.\n",
      "#\n",
      "# There is a special exception for API mobileview to allow dynamic\n",
      "# mobile web &amp; app views to load section content.\n",
      "# These views aren't HTTP-cached but use parser cache aggressively\n",
      "# and don't expose special: pages etc.\n",
      "#\n",
      "# Another exception is for REST API documentation, located at\n",
      "# /api/rest_v1/?doc.\n",
      "#\n",
      "User-agent: *\n",
      "Allow: /w/api.php?action=mobileview&amp;\n",
      "Allow: /w/load.php?\n",
      "Allow: /api/rest_v1/?doc\n",
      "Disallow: /w/\n",
      "Disallow: /api/\n",
      "Disallow: /trap/\n",
      "Disallow: /wiki/Special:\n",
      "Disallow: /wiki/Spezial:\n",
      "Disallow: /wiki/Spesial:\n",
      "Disallow: /wiki/Special%3A\n",
      "Disallow: /wiki/Spezial%3A\n",
      "Disallow: /wiki/Spesial%3A\n",
      "\n",
      "#\n",
      "# ar:\n",
      "Disallow: /wiki/%D8%AE%D8%A7%D8%B5:Search\n",
      "Disallow: /wiki/%D8%AE%D8%A7%D8%B5%3ASearch\n",
      "#\n",
      "# dewiki:\n",
      "# T6937\n",
      "# sensible deletion and meta user discussion pages:\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schkandidaten/\n",
      "Disallow: /wiki/Wikipedia:Löschkandidaten/\n",
      "Disallow: /wiki/Wikipedia:Vandalensperrung/\n",
      "Disallow: /wiki/Wikipedia:Benutzersperrung/\n",
      "Disallow: /wiki/Wikipedia:Vermittlungsausschuss/\n",
      "Disallow: /wiki/Wikipedia:Administratoren/Probleme/\n",
      "Disallow: /wiki/Wikipedia:Adminkandidaturen/\n",
      "Disallow: /wiki/Wikipedia:Qualitätssicherung/\n",
      "Disallow: /wiki/Wikipedia:Qualit%C3%A4tssicherung/\n",
      "# 4937#5\n",
      "Disallow: /wiki/Wikipedia:Vandalismusmeldung/\n",
      "Disallow: /wiki/Wikipedia:Gesperrte_Lemmata/\n",
      "Disallow: /wiki/Wikipedia:Löschprüfung/\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schprüfung/\n",
      "Disallow: /wiki/Wikipedia:Administratoren/Notizen/\n",
      "Disallow: /wiki/Wikipedia:Schiedsgericht/Anfragen/\n",
      "Disallow: /wiki/Wikipedia:L%C3%B6schpr%C3%BCfung/\n",
      "# T14111\n",
      "Disallow: /wiki/Wikipedia:Checkuser/\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Checkuser/\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Adminkandidaturen/\n",
      "# T15961\n",
      "Disallow: /wiki/Wikipedia:Spam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia%3ASpam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia_Diskussion:Spam-Blacklist-Log\n",
      "Disallow: /wiki/Wikipedia_Diskussion%3ASpam-Blacklist-Log\n",
      "#\n",
      "# enwiki:\n",
      "# Folks get annoyed when VfD discussions end up the number 1 google hit for\n",
      "# their name. See T6776\n",
      "Disallow: /wiki/Wikipedia:Articles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Pages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3APages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Miscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AMiscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia:Miscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia%3AMiscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia:Protected_titles/\n",
      "Disallow: /wiki/Wikipedia%3AProtected_titles/\n",
      "# T15398\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam/\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Spam/\n",
      "# T16075\n",
      "Disallow: /wiki/MediaWiki:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki%3ASpam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk%3ASpam-blacklist\n",
      "# T13261\n",
      "Disallow: /wiki/Wikipedia:Requests_for_arbitration/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_arbitration/\n",
      "Disallow: /wiki/Wikipedia:Requests_for_comment/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_comment/\n",
      "Disallow: /wiki/Wikipedia:Requests_for_adminship/\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_adminship/\n",
      "# T12288\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Pages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3APages_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellany_for_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellaneous_deletion/\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellaneous_deletion/\n",
      "# T16793\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia:Changing_username/\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username/\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username/\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username/\n",
      "#\n",
      "# eswiki:\n",
      "# T8746\n",
      "Disallow: /wiki/Wikipedia:Consultas_de_borrado/\n",
      "Disallow: /wiki/Wikipedia%3AConsultas_de_borrado/\n",
      "#\n",
      "# fiwiki:\n",
      "# T10695\n",
      "Disallow: /wiki/Wikipedia:Poistettavat_sivut\n",
      "Disallow: /wiki/K%C3%A4ytt%C3%A4j%C3%A4:\n",
      "Disallow: /wiki/Käyttäjä:\n",
      "Disallow: /wiki/Keskustelu_k%C3%A4ytt%C3%A4j%C3%A4st%C3%A4:\n",
      "Disallow: /wiki/Keskustelu_käyttäjästä:\n",
      "Disallow: /wiki/Wikipedia:Yll%C3%A4pit%C3%A4j%C3%A4t/\n",
      "Disallow: /wiki/Wikipedia:Ylläpitäjät/\n",
      "#\n",
      "# hewiki:\n",
      "Disallow: /wiki/%D7%9E%D7%99%D7%95%D7%97%D7%93:Search\n",
      "Disallow: /wiki/%D7%9E%D7%99%D7%95%D7%97%D7%93%3ASearch\n",
      "#T11517\n",
      "Disallow: /wiki/ויקיפדיה:רשימת_מועמדים_למחיקה/\n",
      "Disallow: /wiki/ויקיפדיה%3Aרשימת_מועמדים_למחיקה/\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%A8%D7%A9%D7%99%D7%9E%D7%AA_%D7%9E%D7%95%D7%A2%D7%9E%D7%93%D7%99%D7%9D_%D7%9C%D7%9E%D7%97%D7%99%D7%A7%D7%94/\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%A8%D7%A9%D7%99%D7%9E%D7%AA_%D7%9E%D7%95%D7%A2%D7%9E%D7%93%D7%99%D7%9D_%D7%9C%D7%9E%D7%97%D7%99%D7%A7%D7%94/\n",
      "Disallow: /wiki/ויקיפדיה:ערכים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/ויקיפדיה%3Aערכים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%A2%D7%A8%D7%9B%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%A2%D7%A8%D7%9B%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/ויקיפדיה:דפים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/ויקיפדיה%3Aדפים_לא_קיימים_ומוגנים\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94:%D7%93%D7%A4%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "Disallow: /wiki/%D7%95%D7%99%D7%A7%D7%99%D7%A4%D7%93%D7%99%D7%94%3A%D7%93%D7%A4%D7%99%D7%9D_%D7%9C%D7%90_%D7%A7%D7%99%D7%99%D7%9E%D7%99%D7%9D_%D7%95%D7%9E%D7%95%D7%92%D7%A0%D7%99%D7%9D\n",
      "#\n",
      "# huwiki:\n",
      "Disallow: /wiki/Speci%C3%A1lis:Search\n",
      "Disallow: /wiki/Speci%C3%A1lis%3ASearch\n",
      "#\n",
      "# itwiki:\n",
      "# T7545\n",
      "Disallow: /wiki/Wikipedia:Pagine_da_cancellare\n",
      "Disallow: /wiki/Wikipedia%3APagine_da_cancellare\n",
      "Disallow: /wiki/Wikipedia:Utenti_problematici\n",
      "Disallow: /wiki/Wikipedia%3AUtenti_problematici\n",
      "Disallow: /wiki/Wikipedia:Vandalismi_in_corso\n",
      "Disallow: /wiki/Wikipedia%3AVandalismi_in_corso\n",
      "Disallow: /wiki/Wikipedia:Amministratori\n",
      "Disallow: /wiki/Wikipedia%3AAmministratori\n",
      "Disallow: /wiki/Wikipedia:Proposte_di_cancellazione_semplificata\n",
      "Disallow: /wiki/Wikipedia%3AProposte_di_cancellazione_semplificata\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito\n",
      "Disallow: /wiki/Categoria%3ADa_cancellare_subito\n",
      "Disallow: /wiki/Wikipedia:Sospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Wikipedia%3ASospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Categoria:Da_controllare_per_copyright\n",
      "Disallow: /wiki/Categoria%3ADa_controllare_per_copyright\n",
      "Disallow: /wiki/Progetto:Rimozione_contributi_sospetti\n",
      "Disallow: /wiki/Progetto%3ARimozione_contributi_sospetti\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Categoria%3ADa_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Progetto:Cococo\n",
      "Disallow: /wiki/Progetto%3ACococo\n",
      "Disallow: /wiki/Discussioni_progetto:Cococo\n",
      "Disallow: /wiki/Discussioni_progetto%3ACococo\n",
      "#\n",
      "# jawiki\n",
      "Disallow: /wiki/%E7%89%B9%E5%88%A5:Search\n",
      "Disallow: /wiki/%E7%89%B9%E5%88%A5%3ASearch\n",
      "# T7239\n",
      "Disallow: /wiki/Wikipedia:%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC/\n",
      "Disallow: /wiki/Wikipedia%3A%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC/\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A9%E7%94%A8%E8%80%85%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AE%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC\n",
      "Disallow: /wiki/Wikipedia%3A%E5%88%A9%E7%94%A8%E8%80%85%E3%83%9A%E3%83%BC%E3%82%B8%E3%81%AE%E5%89%8A%E9%99%A4%E4%BE%9D%E9%A0%BC\n",
      "# nowiki\n",
      "# T13432\n",
      "Disallow: /wiki/Bruker:\n",
      "Disallow: /wiki/Bruker%3A\n",
      "Disallow: /wiki/Brukerdiskusjon\n",
      "Disallow: /wiki/Wikipedia:Administratorer\n",
      "Disallow: /wiki/Wikipedia%3AAdministratorer\n",
      "Disallow: /wiki/Wikipedia-diskusjon:Administratorer\n",
      "Disallow: /wiki/Wikipedia-diskusjon%3AAdministratorer\n",
      "Disallow: /wiki/Wikipedia:Sletting\n",
      "Disallow: /wiki/Wikipedia%3ASletting\n",
      "Disallow: /wiki/Wikipedia-diskusjon:Sletting\n",
      "Disallow: /wiki/Wikipedia-diskusjon%3ASletting\n",
      "#\n",
      "# plwiki\n",
      "# T10067\n",
      "Disallow: /wiki/Wikipedia:Strony_do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia%3AStrony_do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia:Do_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia%3ADo_usuni%C4%99cia\n",
      "Disallow: /wiki/Wikipedia:SDU/\n",
      "Disallow: /wiki/Wikipedia%3ASDU/\n",
      "Disallow: /wiki/Wikipedia:Strony_podejrzane_o_naruszenie_praw_autorskich\n",
      "Disallow: /wiki/Wikipedia%3AStrony_podejrzane_o_naruszenie_praw_autorskich\n",
      "#\n",
      "# ptwiki:\n",
      "# T7394\n",
      "Disallow: /wiki/Wikipedia:Páginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia:P%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia%3AP%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discussão:Páginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discuss%C3%A3o:P%C3%A1ginas_para_eliminar/\n",
      "Disallow: /wiki/Wikipedia_Discuss%C3%A3o%3AP%C3%A1ginas_para_eliminar/\n",
      "#\n",
      "# rowiki:\n",
      "# T14546\n",
      "Disallow: /wiki/Wikipedia:Pagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Wikipedia%3APagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Discu%C5%A3ie_Wikipedia:Pagini_de_%C5%9Fters\n",
      "Disallow: /wiki/Discu%C5%A3ie_Wikipedia%3APagini_de_%C5%9Fters\n",
      "#\n",
      "# ruwiki:\n",
      "Disallow: /wiki/%D0%A1%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5:Search\n",
      "Disallow: /wiki/%D0%A1%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D1%8C%D0%BD%D1%8B%D0%B5%3ASearch\n",
      "#\n",
      "# svwiki:\n",
      "# T12229\n",
      "Disallow: /wiki/Wikipedia%3ASidor_f%C3%B6reslagna_f%C3%B6r_radering\n",
      "Disallow: /wiki/Wikipedia:Sidor_f%C3%B6reslagna_f%C3%B6r_radering\n",
      "Disallow: /wiki/Wikipedia:Sidor_föreslagna_för_radering\n",
      "Disallow: /wiki/Användare\n",
      "Disallow: /wiki/Anv%C3%A4ndare\n",
      "Disallow: /wiki/Användardiskussion\n",
      "Disallow: /wiki/Anv%C3%A4ndardiskussion\n",
      "Disallow: /wiki/Wikipedia:Skyddade_sidnamn\n",
      "Disallow: /wiki/Wikipedia%3ASkyddade_sidnamn\n",
      "# T13291\n",
      "Disallow: /wiki/Wikipedia:Sidor_som_bör_raderas\n",
      "Disallow: /wiki/Wikipedia:Sidor_som_b%C3%B6r_raderas\n",
      "Disallow: /wiki/Wikipedia%3ASidor_som_b%C3%B6r_raderas\n",
      "#\n",
      "# zhwiki:\n",
      "# T7104\n",
      "Disallow: /wiki/Wikipedia:删除投票/侵权\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A0%E9%99%A4%E6%8A%95%E7%A5%A8/%E4%BE%B5%E6%9D%83\n",
      "Disallow: /wiki/Wikipedia:删除投票和请求\n",
      "Disallow: /wiki/Wikipedia:%E5%88%A0%E9%99%A4%E6%8A%95%E7%A5%A8%E5%92%8C%E8%AF%B7%E6%B1%82\n",
      "Disallow: /wiki/Category:快速删除候选\n",
      "Disallow: /wiki/Category:%E5%BF%AB%E9%80%9F%E5%88%A0%E9%99%A4%E5%80%99%E9%80%89\n",
      "Disallow: /wiki/Category:维基百科需要翻译的文章\n",
      "Disallow: /wiki/Category:%E7%BB%B4%E5%9F%BA%E7%99%BE%E7%A7%91%E9%9C%80%E8%A6%81%E7%BF%BB%E8%AF%91%E7%9A%84%E6%96%87%E7%AB%A0\n",
      "#\n",
      "# sister projects\n",
      "#\n",
      "# enwikinews:\n",
      "# T7340\n",
      "Disallow: /wiki/Portal:Prepared_stories/\n",
      "Disallow: /wiki/Portal%3APrepared_stories/\n",
      "#\n",
      "# itwikinews\n",
      "# T11138\n",
      "Disallow: /wiki/Wikinotizie:Richieste_di_cancellazione\n",
      "Disallow: /wiki/Wikinotizie:Sospette_violazioni_di_copyright\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito\n",
      "Disallow: /wiki/Categoria:Da_cancellare_subito_per_violazione_integrale_copyright\n",
      "Disallow: /wiki/Wikinotizie:Storie_in_preparazione\n",
      "#\n",
      "# enwikiquote:\n",
      "# T17095\n",
      "Disallow: /wiki/Wikiquote:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote_talk:Votes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote_talk%3AVotes_for_deletion/\n",
      "Disallow: /wiki/Wikiquote:Votes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote%3AVotes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote_talk:Votes_for_deletion_archive/\n",
      "Disallow: /wiki/Wikiquote_talk%3AVotes_for_deletion_archive/\n",
      "#\n",
      "# enwikibooks\n",
      "Disallow: /wiki/Wikibooks:Votes_for_deletion\n",
      "#\n",
      "# working...\n",
      "Disallow: /wiki/Fundraising_2007/comments\n",
      "#\n",
      "#\n",
      "#\n",
      "#----------------------------------------------------------#\n",
      "#\n",
      "#\n",
      "#\n",
      " # <!-- Please do not remove the space at the start of this line, it breaks the rendering.  http://www.robotstxt.org/orig.html says spaces before comments are OK. --></p><pre>\n",
      "#\n",
      "# Localisable part of robots.txt for en.wikipedia.org\n",
      "#\n",
      "# Edit at https://en.wikipedia.org/w/index.php?title=MediaWiki:Robots.txt&amp;action=edit\n",
      "# Don't add newlines here. All rules set here are active for every user-agent.\n",
      "#\n",
      "# Please check any changes using a syntax validator such as http://tool.motoricerca.info/robots-checker.phtml\n",
      "# Enter https://en.wikipedia.org/robots.txt as the URL to check.\n",
      "#\n",
      "# https://bugzilla.wikimedia.org/show_bug.cgi?id=14075\n",
      "Disallow: /wiki/MediaWiki:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki%3ASpam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk:Spam-blacklist\n",
      "Disallow: /wiki/MediaWiki_talk%3ASpam-blacklist\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam\n",
      "Disallow: /wiki/Wikipedia_talk:WikiProject_Spam\n",
      "#\n",
      "# Folks get annoyed when XfD discussions end up the number 1 google hit for\n",
      "# their name. \n",
      "# https://phabricator.wikimedia.org/T16075\n",
      "Disallow: /wiki/Wikipedia:Articles_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Votes_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AVotes_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Pages_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3APages_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Miscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AMiscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Miscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia%3AMiscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia:Categories_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3ACategories_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Templates_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3ATemplates_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Redirects_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3ARedirects_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Deletion_review\n",
      "Disallow: /wiki/Wikipedia%3ADeletion_review\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia:Files_for_deletion\n",
      "Disallow: /wiki/Wikipedia%3AFiles_for_deletion\n",
      "Disallow: /wiki/Wikipedia:Files_for_discussion\n",
      "Disallow: /wiki/Wikipedia%3AFiles_for_discussion\n",
      "Disallow: /wiki/Wikipedia:Possibly_unfree_files\n",
      "Disallow: /wiki/Wikipedia%3APossibly_unfree_files\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T12288\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Votes_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AVotes_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Pages_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3APages_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellany_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Miscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AMiscellaneous_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Templates_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3ATemplates_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Categories_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk%3ACategories_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk:Deletion_review\n",
      "Disallow: /wiki/Wikipedia_talk%3ADeletion_review\n",
      "Disallow: /wiki/Wikipedia_talk:WikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia_talk%3AWikiProject_Deletion_sorting\n",
      "Disallow: /wiki/Wikipedia_talk:Files_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk%3AFiles_for_deletion\n",
      "Disallow: /wiki/Wikipedia_talk:Files_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk%3AFiles_for_discussion\n",
      "Disallow: /wiki/Wikipedia_talk:Possibly_unfree_files\n",
      "Disallow: /wiki/Wikipedia_talk%3APossibly_unfree_files\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia_talk:Copyright_problems\n",
      "Disallow: /wiki/Wikipedia_talk%3ACopyright_problems\n",
      "Disallow: /wiki/Wikipedia:Suspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia%3ASuspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia_talk:Suspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia_talk%3ASuspected_copyright_violations\n",
      "Disallow: /wiki/Wikipedia:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Contributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3AContributor_copyright_investigations\n",
      "Disallow: /wiki/Wikipedia:Protected_titles\n",
      "Disallow: /wiki/Wikipedia%3AProtected_titles\n",
      "Disallow: /wiki/Wikipedia_talk:Protected_titles\n",
      "Disallow: /wiki/Wikipedia_talk%3AProtected_titles\n",
      "Disallow: /wiki/Wikipedia:Articles_for_creation\n",
      "Disallow: /wiki/Wikipedia%3AArticles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk:Articles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticles_for_creation\n",
      "Disallow: /wiki/Wikipedia_talk:Article_wizard\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticle_wizard\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T13261\n",
      "Disallow: /wiki/Wikipedia:Requests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_arbitration\n",
      "Disallow: /wiki/Wikipedia:Requests_for_comment\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_comment\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_comment\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_comment\n",
      "Disallow: /wiki/Wikipedia:Requests_for_adminship\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_adminship\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_adminship\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_adminship\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T14111\n",
      "Disallow: /wiki/Wikipedia:Requests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_checkuser\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_checkuser\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T15398\n",
      "Disallow: /wiki/Wikipedia:WikiProject_Spam\n",
      "Disallow: /wiki/Wikipedia%3AWikiProject_Spam\n",
      "#\n",
      "# https://phabricator.wikimedia.org/T16793\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia:Changing_username\n",
      "Disallow: /wiki/Wikipedia%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "Disallow: /wiki/Wikipedia_talk:Changing_username\n",
      "Disallow: /wiki/Wikipedia_talk%3AChanging_username\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Administrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AAdministrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Administrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AAdministrators%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia:Community_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ACommunity_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Community_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ACommunity_sanction_noticeboard\n",
      "Disallow: /wiki/Wikipedia:Bureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ABureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Bureaucrats%27_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ABureaucrats%27_noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Sockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia%3ASockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia_talk:Sockpuppet_investigations\n",
      "Disallow: /wiki/Wikipedia_talk%3ASockpuppet_investigations\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Neutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ANeutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Neutral_point_of_view/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ANeutral_point_of_view/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:No_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ANo_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:No_original_research/noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ANo_original_research/noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Fringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AFringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Fringe_theories/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AFringe_theories/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Conflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AConflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Conflict_of_interest/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AConflict_of_interest/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Long-term_abuse\n",
      "Disallow: /wiki/Wikipedia%3ALong-term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk:Long-term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk%3ALong-term_abuse\n",
      "Disallow: /wiki/Wikipedia:Long_term_abuse\n",
      "Disallow: /wiki/Wikipedia%3ALong_term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk:Long_term_abuse\n",
      "Disallow: /wiki/Wikipedia_talk%3ALong_term_abuse\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Wikiquette_assistance\n",
      "Disallow: /wiki/Wikipedia%3AWikiquette_assistance\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Abuse_reports\n",
      "Disallow: /wiki/Wikipedia%3AAbuse_reports\n",
      "Disallow: /wiki/Wikipedia_talk:Abuse_reports\n",
      "Disallow: /wiki/Wikipedia_talk%3AAbuse_reports\n",
      "Disallow: /wiki/Wikipedia:Abuse_response\n",
      "Disallow: /wiki/Wikipedia%3AAbuse_response\n",
      "Disallow: /wiki/Wikipedia_talk:Abuse_response\n",
      "Disallow: /wiki/Wikipedia_talk%3AAbuse_response\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Reliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AReliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Reliable_sources/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AReliable_sources/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Suspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia%3ASuspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia_talk:Suspected_sock_puppets\n",
      "Disallow: /wiki/Wikipedia_talk%3ASuspected_sock_puppets\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Biographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia%3ABiographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Biographies_of_living_persons/Noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3ABiographies_of_living_persons/Noticeboard\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Content_noticeboard\n",
      "Disallow: /wiki/Wikipedia%3AContent_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk:Content_noticeboard\n",
      "Disallow: /wiki/Wikipedia_talk%3AContent_noticeboard\n",
      "#\n",
      "Disallow: /wiki/Template:Editnotices\n",
      "Disallow: /wiki/Template%3AEditnotices\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration\n",
      "Disallow: /wiki/Wikipedia%3AArbitration\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration_Committee\n",
      "Disallow: /wiki/Wikipedia%3AArbitration_Committee\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration_Committee\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration_Committee\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Arbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia%3AArbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia_talk:Arbitration_Committee_Elections\n",
      "Disallow: /wiki/Wikipedia_talk%3AArbitration_Committee_Elections\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Mediation_Committee\n",
      "Disallow: /wiki/Wikipedia%3AMediation_Committee\n",
      "Disallow: /wiki/Wikipedia_talk:Mediation_Committee\n",
      "Disallow: /wiki/Wikipedia_talk%3AMediation_Committee\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Mediation_Cabal/Cases\n",
      "Disallow: /wiki/Wikipedia%3AMediation_Cabal/Cases\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Requests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia%3ARequests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia_talk:Requests_for_bureaucratship\n",
      "Disallow: /wiki/Wikipedia_talk%3ARequests_for_bureaucratship\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Administrator_review\n",
      "Disallow: /wiki/Wikipedia%3AAdministrator_review\n",
      "Disallow: /wiki/Wikipedia_talk:Administrator_review\n",
      "Disallow: /wiki/Wikipedia_talk%3AAdministrator_review\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Editor_review\n",
      "Disallow: /wiki/Wikipedia%3AEditor_review\n",
      "Disallow: /wiki/Wikipedia_talk:Editor_review\n",
      "Disallow: /wiki/Wikipedia_talk%3AEditor_review\n",
      "#\n",
      "Disallow: /wiki/Wikipedia:Article_Incubator\n",
      "Disallow: /wiki/Wikipedia%3AArticle_Incubator\n",
      "Disallow: /wiki/Wikipedia_talk:Article_Incubator\n",
      "Disallow: /wiki/Wikipedia_talk%3AArticle_Incubator\n",
      "#\n",
      "Disallow: /wiki/Category:Noindexed_pages\n",
      "Disallow: /wiki/Category%3ANoindexed_pages\n",
      "#\n",
      "# </pre></body></html>\n"
     ]
    }
   ],
   "source": [
    "# Getting all info in a user friendly interface\n",
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Display the name of the most recently added dataset on data.gov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='http://catalog.data.gov/dataset?q=&sort=metadata_created+desc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requesting the url all its info\n",
    "request=requests.get(url).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "table = soup.find_all('li',{'class':'dataset-item has-organization'})\n",
    "TAG_RE=re.compile(r'<[^>]+>')\n",
    "title_recent=TAG_RE.sub('',str(table[0].find_all('h3',{'class':'dataset-heading'}))).replace('[','').replace(']','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most recent dataset: \n",
      "French Frigate Shoals Site P1A 11/1/2002 17-18M\n"
     ]
    }
   ],
   "source": [
    "print(\"Most recent dataset: \")\n",
    "print(title_recent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Number of datasets currently listed on data.gov "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://www.data.gov/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of datasets listed on data.gov\n",
      "300295\n"
     ]
    }
   ],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "table = soup.find_all('div',{'class':'text-center getstarted'})\n",
    "string=''\n",
    "for e in TAG_RE.sub('',str(table[0])).strip():\n",
    "    if e.isdigit():\n",
    "        string+=e\n",
    "print(\"Number of datasets listed on data.gov\")\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index:  0   >>   www.wikipedia.com//wiki/File:Walt_Disney_1946.JPG\n",
      "Index:  1   >>   www.wikipedia.com//wiki/File:Walt_Disney_1942_signature.svg\n",
      "Index:  2   >>   www.wikipedia.com//wiki/File:Walt_Disney_envelope_ca._1921.jpg\n",
      "Index:  3   >>   www.wikipedia.com//wiki/File:Trolley_Troubles_poster.jpg\n",
      "Index:  4   >>   www.wikipedia.com//wiki/File:Steamboat-willie.jpg\n",
      "Index:  5   >>   www.wikipedia.com//wiki/File:Walt_Disney_1935.jpg\n",
      "Index:  6   >>   www.wikipedia.com//wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg\n",
      "Index:  7   >>   www.wikipedia.com//wiki/File:Disney_drawing_goofy.jpg\n",
      "Index:  8   >>   www.wikipedia.com//wiki/File:DisneySchiphol1951.jpg\n",
      "Index:  9   >>   www.wikipedia.com//wiki/File:WaltDisneyplansDisneylandDec1954.jpg\n",
      "Index:  10   >>   www.wikipedia.com//wiki/File:Walt_disney_portrait_right.jpg\n",
      "Index:  11   >>   www.wikipedia.com//wiki/File:Walt_Disney_Grave.JPG\n",
      "Index:  12   >>   www.wikipedia.com//wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg\n",
      "Index:  13   >>   www.wikipedia.com//wiki/File:Disney_Display_Case.JPG\n",
      "Index:  14   >>   www.wikipedia.com//wiki/File:Disney1968.jpg\n",
      "Index:  15   >>   www.wikipedia.com//wiki/File:P_vip.svg\n",
      "Index:  16   >>   www.wikipedia.com//wiki/File:Video-x-generic.svg\n",
      "Index:  17   >>   www.wikipedia.com//wiki/File:Flag_of_Los_Angeles_County,_California.svg\n",
      "Index:  18   >>   www.wikipedia.com//wiki/File:USA_flag_on_television.svg\n"
     ]
    }
   ],
   "source": [
    "images = soup.select('.image')\n",
    "images_links = ['www.wikipedia.com/' + link.attrs['href'] for link in images]\n",
    "counter=-1\n",
    "for item in images_links:\n",
    "    counter+=1\n",
    "    print(\"Index: \",counter,\"  >>  \",item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org/wiki/Pythonidae',\n",
       " 'https://en.wikipedia.org/wiki/Python_(genus)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(mythology)',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Aenus',\n",
       " 'https://en.wikipedia.org/wiki/Python_(painter)',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Byzantium',\n",
       " 'https://en.wikipedia.org/wiki/Python_of_Catana',\n",
       " 'https://en.wikipedia.org/wiki/Python_(film)',\n",
       " 'https://en.wikipedia.org/wiki/Pythons_2',\n",
       " 'https://en.wikipedia.org/wiki/Monty_Python',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Monty)_Pictures',\n",
       " 'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
       " 'https://en.wikipedia.org/wiki/CPython',\n",
       " 'https://en.wikipedia.org/wiki/CMU_Common_Lisp',\n",
       " 'https://en.wikipedia.org/wiki/PERQ#PERQ_3',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Busch_Gardens_Tampa_Bay)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Coney_Island,_Cincinnati,_Ohio)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Efteling)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(automobile_maker)',\n",
       " 'https://en.wikipedia.org/wiki/Python_(Ford_prototype)',\n",
       " 'https://en.wikipedia.org/wiki/Colt_Python',\n",
       " 'https://en.wikipedia.org/wiki/Python_(missile)',\n",
       " 'https://en.wikipedia.org/wiki/Cython',\n",
       " 'https://en.wikipedia.org/wiki/Pyton',\n",
       " 'https://en.wikipedia.org/wiki/File:Disambig_gray.svg',\n",
       " 'https://en.wikipedia.org/wiki/Help:Disambiguation',\n",
       " 'https://en.wikipedia.org/wiki/Help:Category',\n",
       " 'https://en.wikipedia.org/wiki/Category:Disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:Disambiguation_pages_with_short_description',\n",
       " 'https://en.wikipedia.org/wiki/Category:All_article_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:All_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Category:Animal_common_name_disambiguation_pages',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyTalk',\n",
       " 'https://en.wikipedia.org/wiki/Special:MyContributions',\n",
       " 'https://en.wikipedia.org/wiki/Python',\n",
       " 'https://en.wikipedia.org/wiki/Talk:Python',\n",
       " 'https://en.wikipedia.org/wiki/Python',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Main_Page',\n",
       " 'https://en.wikipedia.org/wiki/Portal:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Portal:Featured_content',\n",
       " 'https://en.wikipedia.org/wiki/Portal:Current_events',\n",
       " 'https://en.wikipedia.org/wiki/Special:Random',\n",
       " 'https://en.wikipedia.org/wiki/Help:Contents',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:Community_portal',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChanges',\n",
       " 'https://en.wikipedia.org/wiki/Special:WhatLinksHere/Python',\n",
       " 'https://en.wikipedia.org/wiki/Special:RecentChangesLinked/Python',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:File_Upload_Wizard',\n",
       " 'https://en.wikipedia.org/wiki/Special:SpecialPages',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:About',\n",
       " 'https://en.wikipedia.org/wiki/Wikipedia:General_disclaimer']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "links=[]\n",
    "for item in soup.select('a'):\n",
    "    if 'href' in item.attrs.keys() and item.attrs['href'].startswith('/wiki') :\n",
    "        links.append('https://en.wikipedia.org'+item.attrs['href'])\n",
    "display(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles changed:  18\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Title 2 - The Congress',\n",
       " 'Title 5 - Government Organization and Employees',\n",
       " 'Title 14 - Coast Guard',\n",
       " 'Title 15 - Commerce and Trade',\n",
       " 'Title 17 - Copyrights',\n",
       " 'Title 19 - Customs Duties',\n",
       " 'Title 20 - Education',\n",
       " 'Title 21 - Food and Drugs',\n",
       " 'Title 22 - Foreign Relations and Intercourse',\n",
       " 'Title 28 - Judiciary and Judicial Procedure',\n",
       " 'Title 33 - Navigation and Navigable Waters',\n",
       " 'Title 34 - Crime Control and Law Enforcement',\n",
       " \"Title 38 - Veterans' Benefits\",\n",
       " 'Title 41 - Public Contracts',\n",
       " 'Title 42 - The Public Health and Welfare',\n",
       " 'Title 45 - Railroads',\n",
       " 'Title 46 - Shipping',\n",
       " 'Title 49 - Transportation']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "titles=[]\n",
    "for elem in soup.find_all('div',{'class':'usctitlechanged'}):\n",
    "    elp=TAG_RE.sub('',str(elem)).strip()\n",
    "    titles.append(elp)\n",
    "print(\"Number of titles changed: \",len(titles))\n",
    "print(\"\")\n",
    "display(titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'LAMONT STEPHENSON',\n",
       " 'JASON DEREK BROWN',\n",
       " 'GREG ALYN CARLSON',\n",
       " 'SANTIAGO VILLALBA MEDEROS',\n",
       " 'RAFAEL CARO-QUINTERO',\n",
       " 'ROBERT WILLIAM FISHER',\n",
       " 'ALEXIS FLORES',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'YASER ABDEL SAID']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names=[]\n",
    "for item in soup.find_all('h3',{'class':'title'}):\n",
    "    names.append(item.select('a')[0].string.strip())\n",
    "display(names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "datestimes=[]\n",
    "for item in soup.find_all('td',{'class':'tabev6'}):\n",
    "    for a in item.find_all('a'):\n",
    "        datestimes.append(a.string.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords=[]\n",
    "indic=[]\n",
    "area=[]\n",
    "mag=[]\n",
    "for item in soup.find_all('td',{'class':'tabev1'}):\n",
    "    coords.append(item.string.strip())\n",
    "for item in soup.find_all('td',{'class':'tabev2'}):\n",
    "    if item.string.isupper():\n",
    "        indic.append(item.string.strip())\n",
    "    else:\n",
    "        mag.append(item.string.strip())\n",
    "for item in soup.find_all('td',{'class':'tb_region'}):\n",
    "    area.append(item.string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lat Hemisphere</th>\n",
       "      <th>Long</th>\n",
       "      <th>Long Hemisphere</th>\n",
       "      <th>Magnitude</th>\n",
       "      <th>Area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>11:23:38.7</td>\n",
       "      <td>35.78</td>\n",
       "      <td>N</td>\n",
       "      <td>121.09</td>\n",
       "      <td>W</td>\n",
       "      <td>2.3</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>11:21:38.0</td>\n",
       "      <td>24.15</td>\n",
       "      <td>S</td>\n",
       "      <td>69.51</td>\n",
       "      <td>W</td>\n",
       "      <td>3.6</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>11:08:15.1</td>\n",
       "      <td>37.38</td>\n",
       "      <td>N</td>\n",
       "      <td>20.37</td>\n",
       "      <td>E</td>\n",
       "      <td>3.6</td>\n",
       "      <td>IONIAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>11:07:58.0</td>\n",
       "      <td>15.18</td>\n",
       "      <td>N</td>\n",
       "      <td>94.54</td>\n",
       "      <td>W</td>\n",
       "      <td>4.3</td>\n",
       "      <td>OFF COAST OF OAXACA, MEXICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>10:48:30.5</td>\n",
       "      <td>36.43</td>\n",
       "      <td>N</td>\n",
       "      <td>28.73</td>\n",
       "      <td>E</td>\n",
       "      <td>2.5</td>\n",
       "      <td>DODECANESE IS.-TURKEY BORDER REG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>10:43:54.4</td>\n",
       "      <td>47.55</td>\n",
       "      <td>N</td>\n",
       "      <td>8.17</td>\n",
       "      <td>E</td>\n",
       "      <td>1.5</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>10:41:13.5</td>\n",
       "      <td>37.30</td>\n",
       "      <td>N</td>\n",
       "      <td>20.87</td>\n",
       "      <td>E</td>\n",
       "      <td>3.7</td>\n",
       "      <td>IONIAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>10:39:12.1</td>\n",
       "      <td>38.81</td>\n",
       "      <td>N</td>\n",
       "      <td>122.79</td>\n",
       "      <td>W</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>10:01:56.2</td>\n",
       "      <td>37.42</td>\n",
       "      <td>N</td>\n",
       "      <td>20.88</td>\n",
       "      <td>E</td>\n",
       "      <td>3.8</td>\n",
       "      <td>IONIAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>09:42:54.7</td>\n",
       "      <td>37.83</td>\n",
       "      <td>N</td>\n",
       "      <td>20.75</td>\n",
       "      <td>E</td>\n",
       "      <td>3.5</td>\n",
       "      <td>IONIAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>09:25:07.4</td>\n",
       "      <td>38.00</td>\n",
       "      <td>N</td>\n",
       "      <td>14.33</td>\n",
       "      <td>E</td>\n",
       "      <td>2.6</td>\n",
       "      <td>SICILY, ITALY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>09:15:08.5</td>\n",
       "      <td>45.64</td>\n",
       "      <td>N</td>\n",
       "      <td>26.70</td>\n",
       "      <td>E</td>\n",
       "      <td>2.9</td>\n",
       "      <td>ROMANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>09:05:36.7</td>\n",
       "      <td>38.51</td>\n",
       "      <td>N</td>\n",
       "      <td>43.52</td>\n",
       "      <td>E</td>\n",
       "      <td>2.5</td>\n",
       "      <td>EASTERN TURKEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>08:49:41.8</td>\n",
       "      <td>36.91</td>\n",
       "      <td>N</td>\n",
       "      <td>20.61</td>\n",
       "      <td>E</td>\n",
       "      <td>3.4</td>\n",
       "      <td>CENTRAL MEDITERRANEAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>08:42:18.0</td>\n",
       "      <td>35.24</td>\n",
       "      <td>N</td>\n",
       "      <td>97.73</td>\n",
       "      <td>W</td>\n",
       "      <td>2.4</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>08:17:00.0</td>\n",
       "      <td>1.09</td>\n",
       "      <td>N</td>\n",
       "      <td>78.81</td>\n",
       "      <td>W</td>\n",
       "      <td>3.6</td>\n",
       "      <td>COLOMBIA-ECUADOR BORDER REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>08:08:43.2</td>\n",
       "      <td>36.49</td>\n",
       "      <td>N</td>\n",
       "      <td>28.76</td>\n",
       "      <td>E</td>\n",
       "      <td>3.4</td>\n",
       "      <td>DODECANESE IS.-TURKEY BORDER REG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>07:30:23.2</td>\n",
       "      <td>36.40</td>\n",
       "      <td>N</td>\n",
       "      <td>28.70</td>\n",
       "      <td>E</td>\n",
       "      <td>2.3</td>\n",
       "      <td>DODECANESE IS.-TURKEY BORDER REG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>07:13:06.6</td>\n",
       "      <td>35.22</td>\n",
       "      <td>N</td>\n",
       "      <td>97.70</td>\n",
       "      <td>W</td>\n",
       "      <td>2.1</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>07:10:37.2</td>\n",
       "      <td>59.86</td>\n",
       "      <td>N</td>\n",
       "      <td>141.41</td>\n",
       "      <td>W</td>\n",
       "      <td>2.7</td>\n",
       "      <td>SOUTHEASTERN ALASKA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date        Time    Lat Lat Hemisphere    Long Long Hemisphere  \\\n",
       "0   2018-11-01  11:23:38.7  35.78              N  121.09               W   \n",
       "1   2018-11-01  11:21:38.0  24.15              S   69.51               W   \n",
       "2   2018-11-01  11:08:15.1  37.38              N   20.37               E   \n",
       "3   2018-11-01  11:07:58.0  15.18              N   94.54               W   \n",
       "4   2018-11-01  10:48:30.5  36.43              N   28.73               E   \n",
       "5   2018-11-01  10:43:54.4  47.55              N    8.17               E   \n",
       "6   2018-11-01  10:41:13.5  37.30              N   20.87               E   \n",
       "7   2018-11-01  10:39:12.1  38.81              N  122.79               W   \n",
       "8   2018-11-01  10:01:56.2  37.42              N   20.88               E   \n",
       "9   2018-11-01  09:42:54.7  37.83              N   20.75               E   \n",
       "10  2018-11-01  09:25:07.4  38.00              N   14.33               E   \n",
       "11  2018-11-01  09:15:08.5  45.64              N   26.70               E   \n",
       "12  2018-11-01  09:05:36.7  38.51              N   43.52               E   \n",
       "13  2018-11-01  08:49:41.8  36.91              N   20.61               E   \n",
       "14  2018-11-01  08:42:18.0  35.24              N   97.73               W   \n",
       "15  2018-11-01  08:17:00.0   1.09              N   78.81               W   \n",
       "16  2018-11-01  08:08:43.2  36.49              N   28.76               E   \n",
       "17  2018-11-01  07:30:23.2  36.40              N   28.70               E   \n",
       "18  2018-11-01  07:13:06.6  35.22              N   97.70               W   \n",
       "19  2018-11-01  07:10:37.2  59.86              N  141.41               W   \n",
       "\n",
       "   Magnitude                              Area  \n",
       "0        2.3                CENTRAL CALIFORNIA  \n",
       "1        3.6                ANTOFAGASTA, CHILE  \n",
       "2        3.6                        IONIAN SEA  \n",
       "3        4.3       OFF COAST OF OAXACA, MEXICO  \n",
       "4        2.5  DODECANESE IS.-TURKEY BORDER REG  \n",
       "5        1.5                       SWITZERLAND  \n",
       "6        3.7                        IONIAN SEA  \n",
       "7        2.2               NORTHERN CALIFORNIA  \n",
       "8        3.8                        IONIAN SEA  \n",
       "9        3.5                        IONIAN SEA  \n",
       "10       2.6                     SICILY, ITALY  \n",
       "11       2.9                           ROMANIA  \n",
       "12       2.5                    EASTERN TURKEY  \n",
       "13       3.4         CENTRAL MEDITERRANEAN SEA  \n",
       "14       2.4                          OKLAHOMA  \n",
       "15       3.6    COLOMBIA-ECUADOR BORDER REGION  \n",
       "16       3.4  DODECANESE IS.-TURKEY BORDER REG  \n",
       "17       2.3  DODECANESE IS.-TURKEY BORDER REG  \n",
       "18       2.1                          OKLAHOMA  \n",
       "19       2.7               SOUTHEASTERN ALASKA  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data=pd.DataFrame(np.c_[datestimes,coords[0::2],indic[0::2],coords[1::2],indic[1::2],mag,area])\n",
    "data.columns=['Date','Time','Lat','Lat Hemisphere','Long','Long Hemisphere','Magnitude','Area']\n",
    "data=data.sort_values(['Time','Date'],ascending=False)\n",
    "display(data.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Display the date, days, title, city, country of next 25 Hackevents as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[item.string.strip() if '-' not in item.string else item.string.split('-')[0].strip() for item in soup.find_all('a',{'class':'title'})]\n",
    "city=[item.string.strip() for item in soup.find_all('span',{'class':'city'})]\n",
    "country=[item.string.strip() for item in soup.find_all('span',{'class':'country'})]\n",
    "infodate=[item.string.strip() for item in soup.find_all('span',{'class':'info-date'})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "date=[]\n",
    "for item in infodate:\n",
    "    a=item.split('-')\n",
    "    a[0]=a[0].strip()\n",
    "    a[1]=a[1].strip()\n",
    "    b=a[1].split()\n",
    "    date.append([a[0]+\" \"+b[1],int(b[0])-int(a[0])+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Start Date</th>\n",
       "      <th>Days</th>\n",
       "      <th>Title</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2 November</td>\n",
       "      <td>3</td>\n",
       "      <td>Hack Access Dublin 2017</td>\n",
       "      <td>Dublin</td>\n",
       "      <td>Ireland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 November</td>\n",
       "      <td>3</td>\n",
       "      <td>Disrupt Puerto Rico</td>\n",
       "      <td>San Juan</td>\n",
       "      <td>Puerto Rico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3 November</td>\n",
       "      <td>1</td>\n",
       "      <td>Women's Hackathon</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>HackTheMidlands 3.0</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3 November</td>\n",
       "      <td>1</td>\n",
       "      <td>Women's Hackathon</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3 November</td>\n",
       "      <td>2</td>\n",
       "      <td>jacobsHack! 2018</td>\n",
       "      <td>Bremen</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Start Date Days                    Title        City         Country\n",
       "0   2 November    3  Hack Access Dublin 2017      Dublin         Ireland\n",
       "1   2 November    3      Disrupt Puerto Rico    San Juan     Puerto Rico\n",
       "2   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "3   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "4   3 November    1        Women's Hackathon   St. Louis             USA\n",
       "5   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "6   3 November    2      HackTheMidlands 3.0  Birmingham  United Kingdom\n",
       "7   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "8   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "9   3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "10  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "11  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "12  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "13  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "14  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "15  3 November    1        Women's Hackathon   St. Louis             USA\n",
       "16  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "17  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "18  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "19  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "20  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "21  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "22  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "23  3 November    2         jacobsHack! 2018      Bremen         Germany\n",
       "24  3 November    2         jacobsHack! 2018      Bremen         Germany"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_hack=pd.DataFrame(np.c_[date,title,city,country])\n",
    "final_hack.columns=['Start Date','Days','Title','City','Country']\n",
    "display(final_hack)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'\n",
    "urluser=url+'elonmusk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(urluser).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of tweets:  5836\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_of_tweets=soup.find_all('span',{'class':'ProfileNav-value'})[0].string.strip().replace('.','')\n",
    "print(\"\")\n",
    "print(\"Total number of tweets: \",num_of_tweets)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'\n",
    "urluser=url+'elonmusk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(urluser).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of followers:  23.4 Millions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_of_tweets=soup.find_all('span',{'class':'ProfileNav-value'})[2].string.strip()\n",
    "print(\"\")\n",
    "print(\"Total number of followers: \",str(num_of_tweets).replace('M','Millions').replace(',','.'))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Num of articles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>5734000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Español</td>\n",
       "      <td>1481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>日本語</td>\n",
       "      <td>1124000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deutsch</td>\n",
       "      <td>2228000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Русский</td>\n",
       "      <td>1502000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Français</td>\n",
       "      <td>2047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Italiano</td>\n",
       "      <td>1467000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>中文</td>\n",
       "      <td>1026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Português</td>\n",
       "      <td>1007000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Polski</td>\n",
       "      <td>1303000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Language Num of articles\n",
       "0    English         5734000\n",
       "1    Español         1481000\n",
       "2        日本語         1124000\n",
       "3    Deutsch         2228000\n",
       "4    Русский         1502000\n",
       "5   Français         2047000\n",
       "6   Italiano         1467000\n",
       "7         中文         1026000\n",
       "8  Português         1007000\n",
       "9     Polski         1303000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "infolang=[]\n",
    "for item in soup.select('a'):\n",
    "    try:\n",
    "        lang=item.select('strong')[0].string\n",
    "        num=item.select('bdi')[0].string.replace(u'\\xa0','').replace('+','')\n",
    "        infolang.append([lang,num])\n",
    "    except:\n",
    "        # \"Strong or bdi attributes not in item\"\n",
    "        pass\n",
    "\n",
    "langdf=pd.DataFrame(infolang,columns=['Language','Num of articles'])\n",
    "display(langdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=[]\n",
    "description=[]\n",
    "for item in soup.select('li'):\n",
    "    ap=item.select('h2')\n",
    "    ak=item.select('p')\n",
    "    if not ap==[]:\n",
    "        datasets.append(ap[0].select('a')[0].string)\n",
    "    if not ak==[]:\n",
    "        description.append(ak[0].string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Business and economy</td>\n",
       "      <td>Small businesses, industry, imports, exports a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crime and justice</td>\n",
       "      <td>Courts, police, prison, offenders, borders and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Defence</td>\n",
       "      <td>Armed forces, health and safety, search and re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Education</td>\n",
       "      <td>Students, training, qualifications and the Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Environment</td>\n",
       "      <td>Weather, flooding, rivers, air quality, geolog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Government</td>\n",
       "      <td>Staff numbers and pay, local councillors and d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Government spending</td>\n",
       "      <td>Includes all payments by government department...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Health</td>\n",
       "      <td>Includes smoking, drugs, alcohol, medicine per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mapping</td>\n",
       "      <td>Addresses, boundaries, land ownership, aerial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Society</td>\n",
       "      <td>Employment, benefits, household finances, pove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Towns and cities</td>\n",
       "      <td>Includes housing, urban planning, leisure, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Transport</td>\n",
       "      <td>Airports, roads, freight, electric vehicles, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Title                                        Description\n",
       "0   Business and economy  Small businesses, industry, imports, exports a...\n",
       "1      Crime and justice  Courts, police, prison, offenders, borders and...\n",
       "2                Defence  Armed forces, health and safety, search and re...\n",
       "3              Education  Students, training, qualifications and the Nat...\n",
       "4            Environment  Weather, flooding, rivers, air quality, geolog...\n",
       "5             Government  Staff numbers and pay, local councillors and d...\n",
       "6    Government spending  Includes all payments by government department...\n",
       "7                 Health  Includes smoking, drugs, alcohol, medicine per...\n",
       "8                Mapping  Addresses, boundaries, land ownership, aerial ...\n",
       "9                Society  Employment, benefits, household finances, pove...\n",
       "10      Towns and cities  Includes housing, urban planning, leisure, was...\n",
       "11             Transport  Airports, roads, freight, electric vehicles, p..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "datasdf=pd.DataFrame(np.c_[datasets,description],columns=['Title','Description'])\n",
    "display(datasdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. The total number of publications produced by the GAO (U.S. Government Accountability Office)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://www.gao.gov/browse/date/custom'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of publications: \n",
      "54912\n"
     ]
    }
   ],
   "source": [
    "string=soup.find_all('h2',{'class':'scannableTitle'})[0].string.replace(u'\\xa0','')\n",
    "string2=re.findall('\\((.*?)\\)',string)[0]\n",
    "numberofpub=''.join(re.findall(r'\\d+',string2)[2:])\n",
    "print(\"Number of publications: \")\n",
    "print(numberofpub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15. Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop to list top 10 languages (are sorted by speakers in descending order)\n",
    "counter=0\n",
    "languages=[]\n",
    "for item in soup.select('td'):\n",
    "    ap=item.select('a')\n",
    "    bp=item.select('td')\n",
    "    if not ap==[] and 'title' in ap[0].attrs:\n",
    "        languages.append(ap[0].string)\n",
    "        counter+=1\n",
    "    if counter==10:\n",
    "        break\n",
    "\n",
    "# Nested loop to search languages speakers number\n",
    "counter=0\n",
    "info=[]\n",
    "for item in soup.select('td'):\n",
    "    ap=item.string\n",
    "    if ap!=None:\n",
    "        if len(ap)>=2:\n",
    "            if '%' not in str(ap):\n",
    "                pob=re.findall(r'\\d+',ap)\n",
    "                if type(pob)!=list:\n",
    "                    if int(pob)>20:\n",
    "                        counter+=1\n",
    "                        info.append(pob)\n",
    "                else:\n",
    "                    if pob!=[]:\n",
    "                        if int(pob[0])>20:  # Second element of the list refers to the registers of 2010. First \n",
    "                                            # element refers to registers of 2007\n",
    "                            counter+=1\n",
    "                            info.append(pob[0])\n",
    "    if counter==10:\n",
    "        break        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Native Speakers millions (2007)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin</td>\n",
       "      <td>935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arabic</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Russian</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Punjabi</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Language  Native Speakers millions (2007)\n",
       "0    Mandarin                              935\n",
       "1     Spanish                              390\n",
       "2     English                              365\n",
       "3       Hindi                              295\n",
       "4      Arabic                              280\n",
       "5  Portuguese                              205\n",
       "6     Bengali                              200\n",
       "7     Russian                              160\n",
       "8    Japanese                              125\n",
       "9     Punjabi                               95"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "morelang=pd.DataFrame(np.c_[languages,info],columns=['Language','Native Speakers millions (2007)'])\n",
    "morelang['Native Speakers millions (2007)']=morelang['Native Speakers millions (2007)'].astype('int64')\n",
    "morelang=morelang.sort_values('Native Speakers millions (2007)',ascending=False).reset_index(drop=True)\n",
    "display(morelang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'\n",
    "urluser=url+'elonmusk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(urluser).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0  >>  Also, you’ll be able to drive it from your phone remotely like a big RC car if in line of sight\n",
      "\n",
      "1  >>  Car will drive to your phone location & follow you like a pet if you hold down summon button on Tesla app\n",
      "\n",
      "2  >>  Tesla advanced Summon ready in ~6 weeks! Just an over-the-air software upgrade, so will work on all cars made in past 2 years (Autopilot hardware V2+).\n",
      "\n",
      "3  >>  For those unfamiliar, this uses Tesla Autopark/Summon. Slightly smarter version hopefully ready soon. By next year, a Tesla should be able to drive around a parking lot, find an empty spot, read signs to confirm it’s valid & park.\n",
      "\n",
      "4  >>  Legally required officers of a corporation are president, treasurer & secretary. Guess I have to keep 1st one or it will confuse the authorities.\n",
      "\n",
      "5  >>  Deleted my Tesla titles last week to see what would happen. I’m now the Nothing of Tesla. Seems fine so far.\n",
      "\n",
      "6  >>  Tesla Autopilot Drive on Navigation going to wide release in North America tonight\n",
      "\n",
      "7  >>  On Twitter, likes are rare & criticism is brutal. So hardcore. It’s great.\n",
      "\n",
      "8  >>  Making progress …\n",
      "\n",
      "9  >>  I said dankest not darkest omg\n",
      "\n",
      "10  >>  Deep down, I think Frost secretly preferred the latter\n",
      "\n",
      "11  >>  Flies like an arrow, but fruit flies like a banana\n",
      "\n",
      "12  >>  Time\n",
      "\n",
      "13  >>  Not moths tho\n"
     ]
    }
   ],
   "source": [
    "tweet_items=soup.find_all('p',{'class':'TweetTextSize TweetTextSize--normal js-tweet-text tweet-text'})\n",
    "tweet_text=[]\n",
    "for item in tweet_items:\n",
    "    try:\n",
    "        ap=item.string\n",
    "    except:\n",
    "        pass\n",
    "    else:\n",
    "        if ap!=None:\n",
    "            tweet_text.append(ap)\n",
    "            \n",
    "# Just displaying in a fancy way:\n",
    "for i in range(len(tweet_text)):\n",
    "    print(\"\")\n",
    "    print(i,\" >> \",tweet_text[i].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_movies=soup.find_all('td',{'class':'titleColumn'}) # All elements of movie descriptions and attributes\n",
    "listing=[]\n",
    "for item in reg_movies:\n",
    "    if item.select('a')!=[] and item.select('span')!=[]:\n",
    "        ap=item.select('a')[0].string # Director and actors\n",
    "        bp=item.select('a')[0].attrs['title'] # Title\n",
    "        cp=item.select('span')[0].string.replace('(','').replace(')','') # Year\n",
    "        listing.append([ap,bp,cp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies=pd.DataFrame(listing,columns=['Title','Director, Actors','Year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director, Actors</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>Frank Darabont (dir.), Tim Robbins, Morgan Fre...</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>Francis Ford Coppola (dir.), Marlon Brando, Al...</td>\n",
       "      <td>1972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El padrino: Parte II</td>\n",
       "      <td>Francis Ford Coppola (dir.), Al Pacino, Robert...</td>\n",
       "      <td>1974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>Christopher Nolan (dir.), Christian Bale, Heat...</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La lista de Schindler</td>\n",
       "      <td>Steven Spielberg (dir.), Liam Neeson, Ralph Fi...</td>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El señor de los anillos: El retorno del rey</td>\n",
       "      <td>Peter Jackson (dir.), Elijah Wood, Viggo Morte...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>Quentin Tarantino (dir.), John Travolta, Uma T...</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>El bueno, el feo y el malo</td>\n",
       "      <td>Sergio Leone (dir.), Clint Eastwood, Eli Wallach</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>El club de la lucha</td>\n",
       "      <td>David Fincher (dir.), Brad Pitt, Edward Norton</td>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Title  \\\n",
       "0                              Cadena perpetua   \n",
       "1                                   El padrino   \n",
       "2                         El padrino: Parte II   \n",
       "3                          El caballero oscuro   \n",
       "4                        12 hombres sin piedad   \n",
       "5                        La lista de Schindler   \n",
       "6  El señor de los anillos: El retorno del rey   \n",
       "7                                 Pulp Fiction   \n",
       "8                   El bueno, el feo y el malo   \n",
       "9                          El club de la lucha   \n",
       "\n",
       "                                    Director, Actors  Year  \n",
       "0  Frank Darabont (dir.), Tim Robbins, Morgan Fre...  1994  \n",
       "1  Francis Ford Coppola (dir.), Marlon Brando, Al...  1972  \n",
       "2  Francis Ford Coppola (dir.), Al Pacino, Robert...  1974  \n",
       "3  Christopher Nolan (dir.), Christian Bale, Heat...  2008  \n",
       "4      Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb  1957  \n",
       "5  Steven Spielberg (dir.), Liam Neeson, Ralph Fi...  1993  \n",
       "6  Peter Jackson (dir.), Elijah Wood, Viggo Morte...  2003  \n",
       "7  Quentin Tarantino (dir.), John Travolta, Uma T...  1994  \n",
       "8   Sergio Leone (dir.), Clint Eastwood, Eli Wallach  1966  \n",
       "9     David Fincher (dir.), Brad Pitt, Edward Norton  1999  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(movies.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "request=requests.get(url).content\n",
    "soup = BeautifulSoup(request, \"lxml\")\n",
    "reg_movies=soup.find_all('td',{'class':'titleColumn'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Director, Actors</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>El bueno, el feo y el malo</td>\n",
       "      <td>Sergio Leone (dir.), Clint Eastwood, Eli Wallach</td>\n",
       "      <td>1966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tiburón</td>\n",
       "      <td>Steven Spielberg (dir.), Roy Scheider, Robert ...</td>\n",
       "      <td>1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El golpe</td>\n",
       "      <td>George Roy Hill (dir.), Paul Newman, Robert Re...</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>Lee Unkrich (dir.), Tom Hanks, Tim Allen</td>\n",
       "      <td>2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>La caza</td>\n",
       "      <td>Thomas Vinterberg (dir.), Mads Mikkelsen, Thom...</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Luna de papel</td>\n",
       "      <td>Peter Bogdanovich (dir.), Ryan O'Neal, Tatum O...</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>El puente sobre el río Kwai</td>\n",
       "      <td>David Lean (dir.), William Holden, Alec Guinness</td>\n",
       "      <td>1957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sucedió una noche</td>\n",
       "      <td>Frank Capra (dir.), Clark Gable, Claudette Col...</td>\n",
       "      <td>1934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Lion King</td>\n",
       "      <td>Roger Allers (dir.), Matthew Broderick, Jeremy...</td>\n",
       "      <td>1994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hotel Rwanda</td>\n",
       "      <td>Terry George (dir.), Don Cheadle, Sophie Okonedo</td>\n",
       "      <td>2004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Title  \\\n",
       "0   El bueno, el feo y el malo   \n",
       "1                      Tiburón   \n",
       "2                     El golpe   \n",
       "3                  Toy Story 3   \n",
       "4                      La caza   \n",
       "5                Luna de papel   \n",
       "6  El puente sobre el río Kwai   \n",
       "7            Sucedió una noche   \n",
       "8                The Lion King   \n",
       "9                 Hotel Rwanda   \n",
       "\n",
       "                                    Director, Actors  Year  \n",
       "0   Sergio Leone (dir.), Clint Eastwood, Eli Wallach  1966  \n",
       "1  Steven Spielberg (dir.), Roy Scheider, Robert ...  1975  \n",
       "2  George Roy Hill (dir.), Paul Newman, Robert Re...  1973  \n",
       "3           Lee Unkrich (dir.), Tom Hanks, Tim Allen  2010  \n",
       "4  Thomas Vinterberg (dir.), Mads Mikkelsen, Thom...  2012  \n",
       "5  Peter Bogdanovich (dir.), Ryan O'Neal, Tatum O...  1973  \n",
       "6   David Lean (dir.), William Holden, Alec Guinness  1957  \n",
       "7  Frank Capra (dir.), Clark Gable, Claudette Col...  1934  \n",
       "8  Roger Allers (dir.), Matthew Broderick, Jeremy...  1994  \n",
       "9   Terry George (dir.), Don Cheadle, Sophie Okonedo  2004  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "listing_rand=[]\n",
    "randidx=random.sample(range(len(reg_movies)),10)\n",
    "for ind in randidx:\n",
    "    item=reg_movies[ind]\n",
    "    if item.select('a')!=[] and item.select('span')!=[]:\n",
    "        ap=item.select('a')[0].string # Director and actors\n",
    "        bp=item.select('a')[0].attrs['title'] # Title\n",
    "        cp=item.select('span')[0].string.replace('(','').replace(')','') # Year\n",
    "        listing_rand.append([ap,bp,cp])\n",
    "\n",
    "movies_rand=pd.DataFrame(listing_rand,columns=['Title','Director, Actors','Year'])\n",
    "display(movies_rand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
