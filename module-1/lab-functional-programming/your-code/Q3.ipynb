{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lambda** is a special Python function type that is **anonymous**. By *anonymous* it means a lambda function does not have name. Lambda functions are embedded inside codes so that you don't call them like calling regular Python functions.\n",
    "\n",
    "**`Map`** applies a function to all the items in an input list. The function that is applied can be a standard or a lambda function.\n",
    "\n",
    "For instance, below is an example of multiplying number tuples in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 12, 30]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [(1,2), (3,4), (5,6)]\n",
    "\n",
    "def multiply(num_tuple):\n",
    "    return num_tuple[0]*num_tuple[1]\n",
    "list(map(multiply, items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...is the same as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 12, 30]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = [(1,2), (3,4), (5,6)]\n",
    "list(map(lambda item: item[0]*item[1], items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do we sometimes use `lambda` and `map`? Because, as you see in the example above, they make your code really concise by combining 3 lines of code to 1 line.\n",
    "\n",
    "Besides `map`, there is also **`filter`** that selectively returns elements in an array according to whether you return `True`. There is also **`reduce`** that performs computation on a list of items then returns result.\n",
    "\n",
    "Here is a [good tutorial](http://book.pythontips.com/en/latest/map_filter.html) about `map`, `filter`, and `reduce`. Read it if you are not familiar with how they are used. Then proceed to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, use `filter` and `lambda` to return a list that contains positive numbers only. The output should be:\n",
    "\n",
    "```[1, 4, 5]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "numbers = [1, 4, -1, -100, 0, 5, -99]\n",
    "\n",
    "# Enter your code below\n",
    "\n",
    "positive_num=list(filter(lambda x: x>0, numbers))\n",
    "\n",
    "print(positive_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, use `reduce` and `lambda` to return a string that only contains English terms. The English terms are separated with a whitespace ` `.\n",
    "\n",
    "Hints: \n",
    "\n",
    "* If your Jupyter Notebook cannot import `langdetect`, you need to install it with `pip install langdetect`. If Jupyter Notebook still cannot find the library, try install with `python3 -m pip install langdetect`. This is because you need to install `langdetect` in the same Python run environment where Jupyter Notebook is running.\n",
    "\n",
    "* If a word is English, `langdetect.detect(word)=='en'` will return `True`.\n",
    "\n",
    "Your output should read:\n",
    "\n",
    "```'good morning everyone'```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good morning everyone\n"
     ]
    }
   ],
   "source": [
    "import langdetect\n",
    "from functools import reduce\n",
    "words = ['good morning', '早上好', 'доброго', 'おはようございます', 'everyone', '大家', 'каждый', 'みんな']\n",
    "\n",
    "# Enter your code below\n",
    "\n",
    "english_string=reduce((lambda x,y: x+' '+y if langdetect.detect(y)=='en' else x),words)\n",
    "\n",
    "print(english_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if you still have time, convert your response in Q2 by using `lambda`, `map`, `filter`, or `reduce` where applicable. Enter your function in the cell below. **(Should be Q1, Q2 is for HTML docs)**\n",
    "\n",
    "As you write Python functions, generally you don't want to make your function too long. Long functions are difficult to read and difficult to debug. If a function is getting too long, consider breaking it into sever shorter functions where the main function calls other functions. If anything goes wrong, you can output debug messages in each of the functions to check where exactly the error is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['doc2.txt', 'doc1.txt', 'doc3.txt']\n"
     ]
    }
   ],
   "source": [
    "# Enter your code below\n",
    "\n",
    "# Define doc paths array\n",
    "\n",
    "import os\n",
    "\n",
    "def look_files_format(file_form):\n",
    "    \n",
    "    \"\"\"\n",
    "    look_files_format main function is to find the names of the files with an specific file format\n",
    "    \n",
    "    It take as input the files format.\n",
    "    \n",
    "    Example:\n",
    "        For txt files   >> loook_files_format(txt)\n",
    "        For Excel files >> loook_files_format(xlsx)\n",
    "        For CSV files   >> loook_files_format(csv)\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    docs=[item for item in next(os.walk('./'))[2] if os.path.isfile(os.path.join('./',item)) and item.endswith(file_form)]\n",
    "    return docs\n",
    "\n",
    "docs = []\n",
    "docs=look_files_format('txt')\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bow_from_docs(docs, stop_words=[]):\n",
    "    \n",
    "    # In the function, first define the variables you will use such as `corpus`, `bag_of_words`, and `term_freq`.\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `docs` and read the content of each doc into a string in `corpus`.\n",
    "    Remember to convert the doc content to lowercases and remove punctuation.\n",
    "    \"\"\"\n",
    "\n",
    "    corpus = []\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "    for item in docs:\n",
    "        doc_file=open(item,'r')\n",
    "        while 1:\n",
    "            line=doc_file.readline().replace('.','').replace(',','').strip().lower()\n",
    "            if len(line)==0:\n",
    "                break\n",
    "            corpus.append(line)\n",
    "        doc_file.close()\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus`. Append the terms in each doc into the `bag_of_words` array. The terms in `bag_of_words` \n",
    "    should be unique which means before adding each term you need to check if it's already added to the array.\n",
    "    In addition, check if each term is in the `stop_words` array. Only append the term to `bag_of_words`\n",
    "    if it is not a stop word.\n",
    "    \"\"\"\n",
    "\n",
    "    bag_of_words = []\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "    for item in corpus:\n",
    "        for element in item.split():\n",
    "            if element not in bag_of_words and element!='' and element not in stop_words:\n",
    "                bag_of_words.append(element)\n",
    "    \n",
    "    \"\"\"\n",
    "    Loop `corpus` again. For each doc string, count the number of occurrences of each term in `bag_of_words`. \n",
    "    Create an array for each doc's term frequency and append it to `term_freq`.\n",
    "    \"\"\"\n",
    "    \n",
    "    term_freq = []\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "    for item in corpus:\n",
    "        freq_2=[]\n",
    "        for element in bag_of_words:\n",
    "            if element in item:\n",
    "                freq_2.append(1)\n",
    "            else:\n",
    "                freq_2.append(0)\n",
    "        term_freq.append(freq_2)\n",
    "    \n",
    "    # Now return your output as an object\n",
    "    return {\n",
    "        \"bag_of_words\": bag_of_words,\n",
    "        \"term_freq\": term_freq\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function below with the Bag of Words lab docs (it's easier for you to debug your code). Your output should be:\n",
    "\n",
    "```{'bag_of_words': ['ironhack', 'cool', 'love', 'student'], 'term_freq': [[1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1]]}```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bag_of_words': ['ironhack', 'cool', 'love', 'student'], 'term_freq': [[1, 1, 0, 0], [1, 0, 1, 0], [1, 0, 0, 1]]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import stop_words\n",
    "bow = get_bow_from_docs([\n",
    "    '../../lab-bag-of-words/your-code/doc1.txt', \n",
    "    '../../lab-bag-of-words/your-code/doc2.txt', \n",
    "    '../../lab-bag-of-words/your-code/doc3.txt'],\n",
    "    stop_words.ENGLISH_STOP_WORDS\n",
    ")\n",
    "\n",
    "print(bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    corpus=[]\n",
    "    for item in docs:\n",
    "        doc_file=open(item,'r')\n",
    "        while 1:\n",
    "            line=doc_file.readline().replace('.','').replace(',','').strip().lower()\n",
    "            if len(line)==0:\n",
    "                break\n",
    "            corpus.append(line)\n",
    "        doc_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love ironhack', 'ironhack is cool', 'i am a student at ironhack']\n"
     ]
    }
   ],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "    bag_of_words = []\n",
    "\n",
    "    # Write your code here\n",
    "\n",
    "    for item in corpus:\n",
    "        for element in item.split():\n",
    "            if element not in bag_of_words and element!='' and element not in stop_words.ENGLISH_STOP_WORDS:\n",
    "                bag_of_words.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['love', 'ironhack', 'cool', 'student']\n"
     ]
    }
   ],
   "source": [
    "print(bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Generator expression must be parenthesized if not sole argument (<ipython-input-39-471193cd4741>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-471193cd4741>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    reduce((lambda x,y: x+' '+y if y not in stop_words.ENGLISH_STOP_WORDS and y not in x else x),corp.split(' ') for corp in corpus)\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Generator expression must be parenthesized if not sole argument\n"
     ]
    }
   ],
   "source": [
    "reduce((lambda x,y: x+' '+y if y not in stop_words.ENGLISH_STOP_WORDS and y not in x else x),corp.split(' ') for corp in corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
