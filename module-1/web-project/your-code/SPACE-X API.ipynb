{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEB-PROJECT - PART 1: API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. SPACE-X API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import pandas as pd\n",
    "import os,datetime\n",
    "import numpy as np\n",
    "date=datetime.datetime.now().date().isoformat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating data storage folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "destfolder='./Data'\n",
    "if not os.path.exists(destfolder):\n",
    "    os.mkdir(destfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Company info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Info of Space X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "api='https://api.spacexdata.com' # API URL\n",
    "cinfo='/v3/info' # COMPANY INFO\n",
    "req_SX_info=api+cinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  File ./Data/Space_X_info.csv already exists\n",
      "\n",
      ">>  Please, continue with Starman Information Retrieve  <<\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is not the CSV file for SPACE X general Info\n",
    "if not os.path.exists(destfolder+\"/Space_X_info.csv\"):\n",
    "    \n",
    "    response = requests.get(req_SX_info)\n",
    "    result = response.json()\n",
    "\n",
    "    info=json_normalize(result).T\n",
    "    info.columns=['Info']\n",
    "    info.to_csv(destfolder+\"/Space_X_info.csv\")\n",
    "\n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"  File \"+destfolder+\"/Space_X_info.csv already exists\")\n",
    "    print(\"\")\n",
    "    print(\">>  Please, continue with Starman Information Retrieve  <<\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Upcoming Launchs Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlrockets='https://api.spacexdata.com/v3/launches/upcoming'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination=destfolder+\"/\"+date+\"_Space_X_Upcoming_Launchs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  File  ./Data/2018-11-01_Space_X_Upcoming_Launchs.csv\n",
      "  Already exists\n",
      "\n",
      ">>  Please, continue with Starman Information Retrieve  <<\n"
     ]
    }
   ],
   "source": [
    "# Checking if there is not the CSV file for SPACE X Upcoming Launchs\n",
    "if not os.path.exists(destination):\n",
    "    \n",
    "    response = requests.get(urlrockets)\n",
    "    result = response.json()\n",
    "\n",
    "    upcoming_launches=json_normalize(result)\n",
    "    \n",
    "    # Retrieving original columns names\n",
    "    cols=(upcoming_launches.columns).unique().tolist()\n",
    "    # And obtaining the unique values of columns name list\n",
    "    upcoming_launches=upcoming_launches[cols]\n",
    "    \n",
    "    # Un-nesting the Attribute rocket.first_stage.cores\n",
    "    mydicts_1=upcoming_launches['rocket.first_stage.cores']\n",
    "    \n",
    "    # Concatenating all internal dicts inside mydicts_1\n",
    "    data_1st_stage=pd.concat([pd.Series(d[0]) for d in mydicts_1], axis=1).T\n",
    "    \n",
    "    # Defining rocket.first_stage.cores nested attribute new names \n",
    "    data_1st_stage.columns=['rocket.first_stage.cores.'+item for item in data_1st_stage.columns]\n",
    "\n",
    "    # Same steps for attribute rocket.first_stage.payloads\n",
    "    mydicts_2=upcoming_launches['rocket.second_stage.payloads']\n",
    "\n",
    "    data_2nd_stage=pd.concat([pd.Series(d[0]) for d in mydicts_1], axis=1).T\n",
    "    data_2nd_stage.columns=['rocket.second_stage.payloads.'+item for item in data_2nd_stage.columns]\n",
    "    \n",
    "    # Concatenating both UN-NESTED COLUMNS OBTAINED in the lines above\n",
    "    final_upcoming=pd.concat([upcoming_launches[upcoming_launches.columns.tolist()[:28]],data_1st_stage,\n",
    "                              upcoming_launches[upcoming_launches.columns.tolist()[30:34]],data_2nd_stage,\n",
    "                              upcoming_launches[upcoming_launches.columns.tolist()[36:]]],axis=1)\n",
    "    \n",
    "    # Saving the dataframe as a CSV\n",
    "    final_upcoming.to_csv(destination,index=False)\n",
    "    \n",
    "else:\n",
    "    print(\"\")\n",
    "    print(\"  File \",destination)\n",
    "    print(\"  Already exists\")\n",
    "    print(\"\")\n",
    "    print(\">>  Please, continue with Starman Information Retrieve  <<\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Starman Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlstarman='https://api.spacexdata.com/v3/roadster'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(urlstarman)\n",
    "result = response.json()\n",
    "\n",
    "# Normalizing data retrieved from starman journey (The first launch with Falcon Heavy)\n",
    "starman=json_normalize(result)\n",
    "\n",
    "# Wrangling process to clean duplicates, just in case\n",
    "starman=starman.drop_duplicates(['period_days'])\n",
    "\n",
    "# If is the first time you run this code it will create a new CSV file\n",
    "if not os.path.exists('./Data/Space_X_Starman.csv'):\n",
    "    starman.to_csv('./Data/Space_X_Starman.csv',index=False)\n",
    "else:\n",
    "    # If not, it will load the stored CSV and compare with the most recent data we have retrieved\n",
    "    data=pd.read_csv('./Data/Space_X_Starman.csv')\n",
    "    data.columns=starman.columns.tolist()\n",
    "    datad=pd.concat([starman,data],axis=0,sort=True)\n",
    "    datad=datad.drop_duplicates(['period_days'])\n",
    "    datad.to_csv('./Data/Space_X_Starman.csv',index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With crontab to make a request each hour\n",
    "These results will be updated every 10 mins, so I'm planning how to develop a script .py to automatize it with crontab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
